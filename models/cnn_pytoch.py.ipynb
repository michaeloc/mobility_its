{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mobility/anaconda/envs/michael_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_just_stops = np.load('../data/sentence_data/sequence_just_stops_window_16_with_categoricals.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequence_just_stops[0]\n",
    "y = sequence_just_stops[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = y==2\n",
    "y[query]=1\n",
    "query = y==3\n",
    "y[query]=2\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=1023)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train, test_size=0.2, random_state=1023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-8.05779846e+00, -3.48836469e+01,  1.30000000e+01,\n",
       "          1.38888889e-01,  1.05430000e+04,  2.35243633e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.05848579e+00, -3.48816272e+01,  2.80000000e+01,\n",
       "          5.55555556e-02,  1.07800000e+04,  1.83674266e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.05936922e+00, -3.48802162e+01,  2.20000000e+01,\n",
       "          9.25925926e-03,  1.09700000e+04,  1.94964560e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06037039e+00, -3.48787604e+01,  2.30000000e+01,\n",
       "          3.70370370e-02,  1.11670000e+04,  1.48375492e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06139707e+00, -3.48796269e+01,  1.90000000e+01,\n",
       "          1.01851852e-01,  1.13270000e+04,  2.54136015e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06337160e+00, -3.48808062e+01,  3.00000000e+01,\n",
       "          0.00000000e+00,  1.15810000e+04,  0.00000000e+00,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06337160e+00, -3.48808062e+01,  3.00000000e+01,\n",
       "          2.59259259e-01,  1.15810000e+04,  4.75121620e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06379622e+00, -3.48808716e+01,  2.00000000e+00,\n",
       "          1.38888889e-01,  1.16280000e+04,  1.40227845e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06478706e+00, -3.48816654e+01,  1.70000000e+01,\n",
       "          0.00000000e+00,  1.17700000e+04,  0.00000000e+00,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06478706e+00, -3.48816654e+01,  1.70000000e+01,\n",
       "          4.62962963e-03,  1.17700000e+04,  3.77951403e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06779924e+00, -3.48832849e+01,  1.80000000e+01,\n",
       "          1.38888889e-01,  1.21690000e+04,  3.40225193e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.07070573e+00, -3.48842962e+01,  3.30000000e+01,\n",
       "          2.77777778e-01,  1.25750000e+04,  3.04097922e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.07089650e+00, -3.48840976e+01,  3.00000000e+00,\n",
       "          1.85185185e-02,  1.26070000e+04,  1.29982937e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.07094220e+00, -3.48839889e+01,  1.00000000e+00,\n",
       "          7.40740741e-02,  1.26170000e+04,  6.87877597e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.07127913e+00, -3.48834643e+01,  9.00000000e+00,\n",
       "          4.62962963e-02,  1.26940000e+04,  1.35466577e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.07191681e+00, -3.48824150e+01,  1.40000000e+01,\n",
       "          1.11111111e-01,  1.28140000e+04,  1.11788815e+01,\n",
       "          5.00000000e+00,  1.00000000e+01]]),\n",
       " array([[-8.07224607e+00, -3.48815911e+01,  1.20000000e+01,\n",
       "          1.38888889e-01,  1.29340000e+04,  2.19973905e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.07224620e+00, -3.48795953e+01,  2.70000000e+01,\n",
       "          5.55555556e-02,  1.31600000e+04,  2.94719824e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.07145328e+00, -3.48770426e+01,  3.30000000e+01,\n",
       "          1.85185185e-02,  1.34400000e+04,  2.66591120e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06972517e+00, -3.48753564e+01,  3.50000000e+01,\n",
       "          1.29629630e-01,  1.37330000e+04,  1.72517759e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06829049e+00, -3.48747421e+01,  2.10000000e+01,\n",
       "          1.94444444e-01,  1.39120000e+04,  9.99871692e-01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06828145e+00, -3.48747420e+01,  0.00000000e+00,\n",
       "          1.94444444e-01,  1.39120000e+04,  1.73211869e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06707443e+00, -3.48757434e+01,  2.10000000e+01,\n",
       "          1.20370370e-01,  1.40910000e+04,  6.44665204e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06653995e+00, -3.48759768e+01,  8.00000000e+00,\n",
       "          1.48148148e-01,  1.41620000e+04,  2.02048193e+02,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06475707e+00, -3.48763767e+01,  2.40000000e+01,\n",
       "          3.70370370e-02,  1.43650000e+04,  8.07919137e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06327819e+00, -3.48794904e+01,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.45340000e+04,  7.45088010e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06327819e+00, -3.48794904e+01,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.45340000e+04,  7.45088010e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06327819e+00, -3.48794904e+01,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.45340000e+04,  7.45088010e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06327819e+00, -3.48794904e+01,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.45340000e+04,  7.45088010e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06327819e+00, -3.48794904e+01,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.45340000e+04,  7.45088010e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06327819e+00, -3.48794904e+01,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.45340000e+04,  7.45088010e+01,\n",
       "          5.00000000e+00,  1.00000000e+01],\n",
       "        [-8.06327819e+00, -3.48794904e+01,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.45340000e+04,  7.45088010e+01,\n",
       "          5.00000000e+00,  1.00000000e+01]]),\n",
       " array([-8.07196243e+00, -3.48823245e+01,  2.00000000e+00,  9.25925926e-02,\n",
       "         1.28320000e+04,  8.67181874e+01,  5.00000000e+00,  1.00000000e+01]),\n",
       " [17.4375,\n",
       "  0.0882523148148148,\n",
       "  11787.0625,\n",
       "  136.32199213876953,\n",
       "  9.823242527292095,\n",
       "  0.08399730262459718,\n",
       "  704.5100663537391,\n",
       "  117.57224962390892,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  10543.0,\n",
       "  0.0,\n",
       "  33.0,\n",
       "  0.2777777777777777,\n",
       "  12814.0,\n",
       "  377.95140290116234,\n",
       "  17.5,\n",
       "  0.06481481481481483,\n",
       "  11699.0,\n",
       "  137.84721100429655],\n",
       " [11.3125,\n",
       "  0.06481481481481481,\n",
       "  14090.4375,\n",
       "  124.80516139831991,\n",
       "  12.897280478845143,\n",
       "  0.07320087176315693,\n",
       "  516.9206864633587,\n",
       "  81.86546209042048,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  12934.0,\n",
       "  0.9998716923814996,\n",
       "  35.0,\n",
       "  0.19444444444444445,\n",
       "  14534.0,\n",
       "  294.71982391205404,\n",
       "  4.0,\n",
       "  0.027777777777777766,\n",
       "  14263.5,\n",
       "  74.5088009519109]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y,batch_size=32):\n",
    "    list_x_b, list_x_a = list(), list()\n",
    "    list_x_target, list_stat_b, list_stat_a = list(), list(), list()\n",
    "    list_y = list()\n",
    "\n",
    "    x1 = x\n",
    "    num_classes = 3\n",
    "    y = (torch.from_numpy(y_train.reshape((-1,1))) == torch.arange(num_classes).reshape(1, num_classes)).float()\n",
    "\n",
    "    for i in range(0,len(x1),batch_size):\n",
    "        if (i+batch_size)<len(x1):\n",
    "            for j in range(i,i+batch_size):\n",
    "                list_x_b.append(x1[j][0])\n",
    "                list_x_a.append(x1[j][1])\n",
    "                list_x_target.append(x1[j][2])\n",
    "                list_stat_b.append(x1[j][3])\n",
    "                list_stat_a.append(x1[j][4])\n",
    "                list_y.append(y[j].data.numpy())\n",
    "            yield [np.array(list_x_b)[:,:,:6],np.array(list_x_b)[:,:,6],np.array(list_x_b)[:,:,7],\n",
    "                    np.array(list_x_a)[:,:,:6],np.array(list_x_a)[:,:,6],np.array(list_x_a)[:,:,7],\n",
    "                    np.array(list_x_target)[:,:6],np.array(list_x_target)[:,6],np.array(list_x_target)[:,7],\n",
    "                    np.array(list_stat_b),\n",
    "                    np.array(list_stat_a)],np.array(list_y)\n",
    "        list_x_b,list_x_a,list_x_target,list_stat_b,list_stat_a,list_y=[],[],[],[],[],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(6,32,16)\n",
    "        self.conv2 = nn.Conv1d(6,32,16)\n",
    "        self.fc1 = nn.Linear(110,64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.fc3 = nn.Linear(32, 3)\n",
    "    \n",
    "    def forward(self,x_before,x_after,x,x_before_stat,x_after_stat):\n",
    "        x_before = F.relu(self.conv1(x_before))\n",
    "        x_after = F.relu(self.conv1(x_after))\n",
    "        \n",
    "        x_before = x_before.view(-1,self.num_flat_features(x_before))\n",
    "        x_after = x_after.view(-1,self.num_flat_features(x_after)) \n",
    "        \n",
    "        concat = torch.cat([x_before_stat,x_before,x,x_after,x_after_stat],dim=1)\n",
    "        \n",
    "        result = F.relu(self.fc1(concat))\n",
    "        result = F.relu(self.fc2(result))\n",
    "        result = self.fc3(result)\n",
    "        return result\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "net = net.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv1d(6, 32, kernel_size=(16,), stride=(1,))\n",
      "  (conv2): Conv1d(6, 32, kernel_size=(16,), stride=(1,))\n",
      "  (fc1): Linear(in_features=110, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15491"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_batches(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def createLossAndOptimizer(net, learning_rate=0.001):\n",
    "    \n",
    "    #Loss function\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    #Optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return(loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
    "    \n",
    "    #Print all of the hyperparameters of the training iteration:\n",
    "    print(\"===== HYPERPARAMETERS =====\")\n",
    "    print(\"batch_size=\", batch_size)\n",
    "    print(\"epochs=\", n_epochs)\n",
    "    print(\"learning_rate=\", learning_rate)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    #Create our loss and optimizer functions\n",
    "    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        #Get training data\n",
    "        train_loader = get_batches(X_train,y_train,batch_size)\n",
    "        n_batches = len(X_train)//batch_size\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        total_acc = 0\n",
    "        partial_acc = 0\n",
    "        \n",
    "        number_of_subepoch = 0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            inputs, labels = data\n",
    "            \n",
    "            input_x_before = Variable(torch.from_numpy(data[0][0].reshape(-1,6,16)).clone())\n",
    "            input_x_after = Variable(torch.from_numpy(data[0][3].reshape(-1,6,16)).clone())\n",
    "            input_x = Variable(torch.from_numpy(data[0][6]).clone())\n",
    "            input_x_before_stat = Variable(torch.from_numpy(data[0][9]).clone())\n",
    "            input_x_after_stat = Variable(torch.from_numpy(data[0][10]).clone())\n",
    "            \n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(input_x_before.cuda(),\n",
    "                          input_x_after.cuda(),\n",
    "                          input_x.cuda(),\n",
    "                          input_x_before_stat.cuda(),\n",
    "                          input_x_after_stat.cuda())\n",
    "            \n",
    "            labels = np.argmax(labels, axis=1)\n",
    "            loss_size = loss(outputs, Variable(torch.from_numpy(labels).clone().long(),requires_grad=False).cuda())\n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_val_loss+= loss_size.item()\n",
    "            partial_acc += torch.sum(torch.argmax(outputs, dim=1) == torch.from_numpy(labels).cuda()).item()/batch_size\n",
    "            number_of_subepoch+=1\n",
    "\n",
    "        print(f'loss:{total_val_loss/number_of_subepoch}')\n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        val_batch = get_batches(X_val,y_val,32)\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_batch,0):\n",
    "                \n",
    "                inputs1,labels1 = data\n",
    "                input_x_before = Variable(torch.from_numpy(data[0][0].reshape(-1,6,16)).clone())\n",
    "                input_x_after = Variable(torch.from_numpy(data[0][3].reshape(-1,6,16)).clone())\n",
    "                input_x = Variable(torch.from_numpy(data[0][6]).clone())\n",
    "                input_x_before_stat = Variable(torch.from_numpy(data[0][9]).clone())\n",
    "                input_x_after_stat = Variable(torch.from_numpy(data[0][10]).clone())\n",
    "                \n",
    "                #Forward pass\n",
    "                val_outputs = net(input_x_before.cuda(),\n",
    "                                  input_x_after.cuda(),\n",
    "                                  input_x.cuda(),\n",
    "                                  input_x_before_stat.cuda(),\n",
    "                                  input_x_after_stat.cuda())\n",
    "                val_loss_size = loss(val_outputs, Variable(torch.from_numpy(labels).clone()).cuda())\n",
    "                total_val_loss += val_loss_size.item()\n",
    "            \n",
    "        print(\"Validation loss = {:.2f}\".format(total_val_loss / i))\n",
    "        \n",
    "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 20\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "loss:0.8751320908853254\n",
      "Validation loss = 4.42\n",
      "loss:0.8688843015198097\n",
      "Validation loss = 4.35\n",
      "loss:0.8643170429803723\n",
      "Validation loss = 4.33\n",
      "loss:0.8677671540239374\n",
      "Validation loss = 4.38\n",
      "loss:0.8626736543187787\n",
      "Validation loss = 4.33\n",
      "loss:0.8618058074090098\n",
      "Validation loss = 4.33\n",
      "loss:0.8587921571848647\n",
      "Validation loss = 4.31\n",
      "loss:0.8653078312403032\n",
      "Validation loss = 4.34\n",
      "loss:0.8618708369961452\n",
      "Validation loss = 4.35\n",
      "loss:0.860145820843664\n",
      "Validation loss = 4.32\n"
     ]
    }
   ],
   "source": [
    "trainNet(net,32,20,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a/= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
