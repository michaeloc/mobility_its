{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_map_stops_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating some labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['label'] != 'init_trip') & (data['label']!='end_trip')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['lat','lng','velocidade','acc','delta_time','delta_space','matricula_id','week_days','hours','months']].values\n",
    "y = data[['label']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting labels distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(x,y):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(np.arange(len(x)),x)\n",
    "    plt.xticks(np.arange(len(x)), ('bus_stop', 'in_route', 'other_stop', 'traffic_light'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop = len(data[data['label']=='bus_stop'])\n",
    "in_route = len(data[data['label']=='in_route'])\n",
    "other_stop = len(data[data['label']=='other_stop'])\n",
    "traffic_light = len(data[data['label']=='traffic_light'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_plot([bus_stop,in_route,other_stop,traffic_light],np.unique(y).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enconding categorical variable\n",
    "<p> Those variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "X[:,6] = lb.fit_transform(X[:,6])\n",
    "X[:,7] = lb.fit_transform(X[:,7])\n",
    "X[:,8] = lb.fit_transform(X[:,8])\n",
    "X[:,9] = lb.fit_transform(X[:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52],\n",
       "       dtype=object),\n",
       " array([0, 1, 2, 3, 4, 5, 6], dtype=object),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23], dtype=object),\n",
       " array([0, 1], dtype=object))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X[:,6]),np.unique(X[:,7]), np.unique(X[:,8]),np.unique(X[:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       x: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    # Get the number of characters per batch and number of batches we can make\n",
    "    characters_per_batch = batch_size*n_steps\n",
    "    n_batches = len(x)//characters_per_batch\n",
    "    # Keep only enough characters to make full batches\n",
    "    x= x[:characters_per_batch*n_batches]\n",
    "    y= y[:characters_per_batch*n_batches]\n",
    "    \n",
    "    # Reshape into batch_size rows\n",
    "    x= x.reshape((-1,n_steps,10))\n",
    "    y= y.reshape((-1,n_steps))\n",
    "    for n in range(0, x.shape[0], batch_size):\n",
    "        # The features\n",
    "        x1 = x[n:n+batch_size]\n",
    "        # The targets, shifted by one\n",
    "        y1 = y[n:n+batch_size]\n",
    "        \n",
    "        yield x1, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_batches(X_train,y_train, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341793, 341793)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = next(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps, features_numeric, features_discrete):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        features: Number of features in batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.float32, [batch_size, num_steps, features_numeric], name='inputs_numeric')\n",
    "    inputs_id = tf.placeholder(tf.int32, [batch_size, num_steps, features_discrete], name='inputs_id') \n",
    "    inputs_m = tf.placeholder(tf.int32, [batch_size, num_steps, features_discrete], name='inputs_month')\n",
    "    inputs_w = tf.placeholder(tf.int32, [batch_size, num_steps, features_discrete], name='inputs_week')\n",
    "    inputs_h = tf.placeholder(tf.int32, [batch_size, num_steps, features_discrete], name='inputs_hour')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    return inputs,inputs_id,inputs_m, inputs_w, inputs_h, targets, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_summaries():\n",
    "    tf_loss = tf.placeholder(tf.float32, shape=None, name='loss_summary')\n",
    "    tf_loss_summary = tf.summary.scalar('loss', tf_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embeddings(n_vocab,n_embedding,inputs, name):\n",
    "    with tf.variable_scope('embeddings'):\n",
    "        embedding = tf.Variable(tf.random_uniform((n_vocab,n_embedding),-1,1), name=name)\n",
    "        embed = tf.nn.embedding_lookup(embedding, inputs)\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    # Use a basic LSTM cell\n",
    "    def build_cell(lstm_size, keep_prob):\n",
    "        # Use a basic LSTM cell\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "\n",
    "        # Add dropout to the cell\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size,embed_id, embed_m, embed_w, embed_h):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        lstm_output: List of output tensors from the LSTM layer\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # Concatenate lstm_output over axis 1 (the columns)\n",
    "    seq_output = tf.concat(lstm_output, axis=1)\n",
    "    # Reshape seq_output to a 2D tensor with lstm_size columns\n",
    "    # -1 porque ele preenche a quantidade de linhas de automaticamente, apenas fixa as colunas\n",
    "    x = tf.reshape(seq_output,[-1,in_size])\n",
    "    \n",
    "    x = tf.concat([x, tf.reshape(embed_id,[-1,10]),tf.reshape(embed_m,[-1,10]), tf.reshape(embed_w,[-1,10]), tf.reshape(embed_h,[-1,10])],1)\n",
    "    print(x)\n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        # Create the weight and bias variables here\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size+40,out_size),stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "    \n",
    "    tf.summary.histogram('softmax_w', softmax_w)\n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits = tf.add(tf.matmul(x,softmax_w), softmax_b)\n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss(logits, targets,num_classes):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # One-hot encode targets and reshape to match logits, one row per sequence per step\n",
    "    y_one_hot = tf.one_hot(targets,num_classes)\n",
    "    y_reshaped =  tf.reshape(y_one_hot,logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_reshaped, logits=logits)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobilityRNN:\n",
    "    \n",
    "    def __init__(self, num_classes=4, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False, features1=6, features2=1):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "#         if sampling == True:\n",
    "#             batch_size, num_steps = 1, 1\n",
    "#         else:\n",
    "        batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.inputs_id, self.inputs_m, self.inputs_w, self.inputs_h, self.targets, self.keep_prob = build_inputs(batch_size,num_steps,features1,features2)\n",
    "                \n",
    "        self.embed_id = build_embeddings(53,10,self.inputs_id,'matricula_id')\n",
    "        self.embed_m = build_embeddings(2,10,self.inputs_m,'month')\n",
    "        self.embed_w = build_embeddings(7,10,self.inputs_w,'week')\n",
    "        self.embed_h = build_embeddings(24,10,self.inputs_h,'hour')\n",
    "        \n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size,num_layers,batch_size,self.keep_prob)\n",
    "\n",
    "        # Run each sequence step through the RNN with tf.nn.dynamic_rnn \n",
    "        outputs, state =tf.nn.dynamic_rnn(cell, self.inputs, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.prediction, self.logits = build_output(outputs,lstm_size,num_classes,self.embed_id,self.embed_m, self.embed_w, self.embed_h)\n",
    "\n",
    "        tf.summary.histogram(\"predictions\", self.prediction)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss =  build_loss(self.logits,self.targets,num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24*8*0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10         # Sequences per batch\n",
    "num_steps = 10          # Number of sequence steps per batch\n",
    "lstm_size = 64         # Size of hidden layers in LSTMs\n",
    "num_layers = 1         # Number of LSTM layers\n",
    "learning_rate = 0.001    # Learning rate\n",
    "keep_prob = 0.5         # Dropout keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_1:0\", shape=(100, 104), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-21-3fd95a9bdaf3>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Epoch: 1/2...  Training Step: 50...  Training loss: 0.7423...  0.4363 sec/batch\n",
      "Epoch: 1/2...  Training Step: 100...  Training loss: 0.4311...  0.5119 sec/batch\n",
      "Epoch: 1/2...  Training Step: 150...  Training loss: 0.3510...  0.4619 sec/batch\n",
      "Epoch: 1/2...  Training Step: 200...  Training loss: 0.4663...  0.5473 sec/batch\n",
      "Epoch: 1/2...  Training Step: 250...  Training loss: 0.3094...  0.4753 sec/batch\n",
      "Epoch: 1/2...  Training Step: 300...  Training loss: 0.3636...  0.5368 sec/batch\n",
      "Epoch: 1/2...  Training Step: 350...  Training loss: 0.3640...  0.3869 sec/batch\n",
      "Epoch: 1/2...  Training Step: 400...  Training loss: 0.2662...  0.5808 sec/batch\n",
      "Epoch: 1/2...  Training Step: 450...  Training loss: 0.2505...  0.7450 sec/batch\n",
      "Epoch: 1/2...  Training Step: 500...  Training loss: 0.4197...  0.5584 sec/batch\n",
      "Epoch: 1/2...  Training Step: 550...  Training loss: 0.4302...  0.6480 sec/batch\n",
      "Epoch: 1/2...  Training Step: 600...  Training loss: 0.2357...  0.6648 sec/batch\n",
      "Epoch: 1/2...  Training Step: 650...  Training loss: 0.2543...  0.5729 sec/batch\n",
      "Epoch: 1/2...  Training Step: 700...  Training loss: 0.3557...  0.6419 sec/batch\n",
      "Epoch: 1/2...  Training Step: 750...  Training loss: 0.2982...  0.4772 sec/batch\n",
      "Epoch: 1/2...  Training Step: 800...  Training loss: 0.3574...  0.7314 sec/batch\n",
      "Epoch: 1/2...  Training Step: 850...  Training loss: 0.3005...  0.6657 sec/batch\n",
      "Epoch: 1/2...  Training Step: 900...  Training loss: 0.2785...  0.5517 sec/batch\n",
      "Epoch: 1/2...  Training Step: 950...  Training loss: 0.2784...  0.5717 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1000...  Training loss: 0.2368...  0.6230 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1050...  Training loss: 0.2877...  0.8698 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1100...  Training loss: 0.4030...  0.5709 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1150...  Training loss: 0.2319...  0.7425 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1200...  Training loss: 0.3035...  0.5926 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1250...  Training loss: 0.2836...  0.6002 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1300...  Training loss: 0.4207...  0.6125 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1350...  Training loss: 0.2365...  0.7417 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1400...  Training loss: 0.2361...  0.6025 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1450...  Training loss: 0.2925...  0.7469 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1500...  Training loss: 0.2318...  0.4103 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1550...  Training loss: 0.3018...  0.5009 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1600...  Training loss: 0.2236...  0.7534 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1650...  Training loss: 0.3090...  0.5989 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1700...  Training loss: 0.2373...  0.7907 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1750...  Training loss: 0.3328...  0.6329 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1800...  Training loss: 0.2821...  0.5922 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1850...  Training loss: 0.1939...  0.4254 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1900...  Training loss: 0.2588...  0.6703 sec/batch\n",
      "Epoch: 1/2...  Training Step: 1950...  Training loss: 0.3425...  0.8102 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2000...  Training loss: 0.2768...  0.9011 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2050...  Training loss: 0.2623...  0.5462 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2100...  Training loss: 0.3599...  0.6197 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2150...  Training loss: 0.2147...  0.3957 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2200...  Training loss: 0.3529...  0.5737 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2250...  Training loss: 0.1841...  0.6223 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2300...  Training loss: 0.2659...  0.7367 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2350...  Training loss: 0.1946...  0.9699 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2400...  Training loss: 0.3636...  0.5281 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2450...  Training loss: 0.1981...  0.8096 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2500...  Training loss: 0.2673...  0.7837 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2550...  Training loss: 0.3545...  0.8821 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2600...  Training loss: 0.2572...  0.9981 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2650...  Training loss: 0.2564...  1.0664 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2700...  Training loss: 0.4026...  0.7277 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2750...  Training loss: 0.2988...  0.7767 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2800...  Training loss: 0.3732...  1.0187 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2850...  Training loss: 0.2043...  0.9077 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2900...  Training loss: 0.1794...  1.0706 sec/batch\n",
      "Epoch: 1/2...  Training Step: 2950...  Training loss: 0.1929...  1.0209 sec/batch\n",
      "Epoch: 1/2...  Training Step: 3000...  Training loss: 0.2305...  1.0926 sec/batch\n",
      "Epoch: 1/2...  Training Step: 3050...  Training loss: 0.4051...  1.0287 sec/batch\n",
      "Epoch: 1/2...  Training Step: 3100...  Training loss: 0.3317...  0.8828 sec/batch\n",
      "Epoch: 1/2...  Training Step: 3150...  Training loss: 0.2652...  1.0877 sec/batch\n",
      "Epoch: 1/2...  Training Step: 3200...  Training loss: 0.3007...  1.0913 sec/batch\n",
      "Epoch: 1/2...  Training Step: 3250...  Training loss: 0.2227...  0.8759 sec/batch\n",
      "Epoch: 1/2...  Training Step: 3300...  Training loss: 0.3543...  1.1807 sec/batch\n",
      "Epoch: 1/2...  Training Step: 3350...  Training loss: 0.1870...  1.3050 sec/batch\n",
      "Epoch: 1/2...  Training Step: 3400...  Training loss: 0.1696...  1.4295 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3450...  Training loss: 0.2688...  1.2803 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3500...  Training loss: 0.2670...  1.1813 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3550...  Training loss: 0.3534...  0.9066 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3600...  Training loss: 0.3717...  1.1707 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3650...  Training loss: 0.3140...  0.8568 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3700...  Training loss: 0.3414...  1.1586 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3750...  Training loss: 0.2253...  0.8726 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3800...  Training loss: 0.2432...  0.7277 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3850...  Training loss: 0.2403...  0.8281 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3900...  Training loss: 0.3092...  1.3476 sec/batch\n",
      "Epoch: 2/2...  Training Step: 3950...  Training loss: 0.2547...  0.9243 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4000...  Training loss: 0.2427...  1.3585 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4050...  Training loss: 0.2347...  0.9343 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4100...  Training loss: 0.2646...  1.1269 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4150...  Training loss: 0.2826...  1.0578 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4200...  Training loss: 0.2671...  0.8833 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4250...  Training loss: 0.2568...  1.3089 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4300...  Training loss: 0.2599...  1.1668 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4350...  Training loss: 0.4265...  1.4750 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4400...  Training loss: 0.3296...  1.3401 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4450...  Training loss: 0.2051...  1.3047 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4500...  Training loss: 0.3260...  1.1020 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4550...  Training loss: 0.2432...  1.5567 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4600...  Training loss: 0.1778...  1.4258 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4650...  Training loss: 0.2251...  1.6641 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4700...  Training loss: 0.2407...  1.4863 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4750...  Training loss: 0.2810...  1.1739 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/2...  Training Step: 4800...  Training loss: 0.1413...  1.6561 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4850...  Training loss: 0.2338...  1.3958 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4900...  Training loss: 0.2830...  1.7119 sec/batch\n",
      "Epoch: 2/2...  Training Step: 4950...  Training loss: 0.3377...  2.0090 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5000...  Training loss: 0.2676...  1.5489 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5050...  Training loss: 0.2968...  1.8679 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5100...  Training loss: 0.2399...  1.9309 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5150...  Training loss: 0.2431...  1.7292 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5200...  Training loss: 0.2773...  1.3986 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5250...  Training loss: 0.2599...  1.6333 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5300...  Training loss: 0.2567...  1.2698 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5350...  Training loss: 0.2095...  1.3624 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5400...  Training loss: 0.3093...  1.6552 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5450...  Training loss: 0.3300...  1.9908 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5500...  Training loss: 0.2182...  1.3263 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5550...  Training loss: 0.2717...  1.9178 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5600...  Training loss: 0.2319...  1.9470 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5650...  Training loss: 0.2107...  1.9760 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5700...  Training loss: 0.2450...  1.7452 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5750...  Training loss: 0.3519...  1.9004 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5800...  Training loss: 0.1849...  1.7139 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5850...  Training loss: 0.2713...  1.8112 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5900...  Training loss: 0.2743...  1.9867 sec/batch\n",
      "Epoch: 2/2...  Training Step: 5950...  Training loss: 0.1446...  1.8307 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6000...  Training loss: 0.2887...  1.4137 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6050...  Training loss: 0.3374...  1.3665 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6100...  Training loss: 0.1766...  1.7770 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6150...  Training loss: 0.3321...  1.6459 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6200...  Training loss: 0.2702...  2.0590 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6250...  Training loss: 0.1905...  1.2637 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6300...  Training loss: 0.4070...  1.2870 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6350...  Training loss: 0.1728...  2.0872 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6400...  Training loss: 0.3028...  1.7349 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6450...  Training loss: 0.2023...  1.5767 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6500...  Training loss: 0.3214...  1.5134 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6550...  Training loss: 0.3089...  2.1917 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6600...  Training loss: 0.1804...  1.4598 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6650...  Training loss: 0.1904...  1.7569 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6700...  Training loss: 0.2468...  2.1311 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6750...  Training loss: 0.3038...  2.0402 sec/batch\n",
      "Epoch: 2/2...  Training Step: 6800...  Training loss: 0.2730...  1.6712 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "# Print losses every N interations\n",
    "print_every_n = 50\n",
    "\n",
    "# Save every N iterations\n",
    "save_every_n = 200\n",
    "\n",
    "model = MobilityRNN(4, batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "if not os.path.exists('summaries'):\n",
    "    os.mkdir('summaries')\n",
    "if not os.path.exists(os.path.join('summaries','first')):\n",
    "    os.mkdir(os.path.join('summaries','first'))\n",
    "    \n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summ_writer = tf.summary.FileWriter(os.path.join('summaries','first'), sess.graph)\n",
    "#     # Use the line below to load a checkpoint and resume training\n",
    "#     #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "#         # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        batch_loss_per_epoch = list()\n",
    "        for x1, y1 in get_batches(X_train,y_train, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x1[:,:,:6],\n",
    "                    model.inputs_id: x1[:,:,6].reshape(10,10,1),\n",
    "                    model.inputs_m: x1[:,:,-1].reshape(10,10,1),\n",
    "                    model.inputs_h: x1[:,:,7].reshape(10,10,1),\n",
    "                    model.inputs_w: x1[:,:,8].reshape(10,10,1),\n",
    "                    model.targets: y1,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "\n",
    "            merge = tf.summary.merge_all()\n",
    "            \n",
    "            summary,batch_loss, new_state, _ = sess.run([merge,model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            \n",
    "            summ_writer.add_summary(summary, counter)\n",
    "            \n",
    "            batch_loss_per_epoch.append(batch_loss)\n",
    "            if (counter % print_every_n == 0):\n",
    "                end = time.time()\n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                      'Training Step: {}... '.format(counter),\n",
    "                      'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                      '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "        \n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/i6834_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i200_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i400_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i600_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i800_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1000_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1200_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1400_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1600_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1800_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2000_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2200_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2400_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2600_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2800_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3000_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3200_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3400_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3600_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3800_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4000_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4200_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4400_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4600_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4800_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5000_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5200_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5400_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5600_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5800_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6000_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6200_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6400_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6600_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6800_l64.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6834_l64.ckpt\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(checkpoint,lstm_size):\n",
    "    model = MobilityRNN(4,batch_size=10, num_steps=10 ,lstm_size=lstm_size,num_layers=1, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    predictions = list()\n",
    "    labels_list = list()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for x1,y1 in get_batches(X_test,y_test,10,10):\n",
    "            feed = {model.inputs: x1[:,:,:6],\n",
    "                    model.inputs_id: x1[:,:,6].reshape(10,10,1),\n",
    "                    model.inputs_m: x1[:,:,-1].reshape(10,10,1),\n",
    "                    model.inputs_h: x1[:,:,7].reshape(10,10,1),\n",
    "                    model.inputs_w: x1[:,:,8].reshape(10,10,1),\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "            predictions.append(preds)\n",
    "            labels_list.append(y1)\n",
    "    return predictions, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_1:0\", shape=(100, 104), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-24-3fd95a9bdaf3>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/i6834_l64.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "samp, y_test_batches = sample(checkpoint,lstm_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def inverse_transform(data, batch=False, reshape=100):\n",
    "    classes = list()\n",
    "    for items in data:\n",
    "        if not batch:\n",
    "            label_idx = np.argmax(items, axis=1).tolist()\n",
    "            list_inverse = list(le.inverse_transform(label_idx))\n",
    "            classes += list_inverse\n",
    "        else:\n",
    "            classes += list(le.inverse_transform(items.reshape(reshape,)))\n",
    "    return classes\n",
    "predict = inverse_transform(samp)\n",
    "y_test_transformed = inverse_transform(y_test_batches,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85400, 85400)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict),len(y_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test_transformed,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 6258  1207   757   118]\n",
      " [  731 65023  2053    92]\n",
      " [  510  1528  3924    73]\n",
      " [ 1714   749   467   196]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(matrix,np.unique(y_test_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
